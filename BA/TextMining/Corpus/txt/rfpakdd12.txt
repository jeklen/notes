Hybrid Random Forests: Advantages of Mixed Trees in Classifying Text Data
Baoxun Xu1, Joshua Zhexue Huang2, Graham Williams2, Junjie Li2, and Yunming Ye1
1 Department of Computer Science, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen 518055, China
2 Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China
amusing002@gmail.com, zx.huang@siat.ac.cn, Graham.Williams@togaware.com, jj.li@siat.ac.cn, yeyunming@hit.edu.cn
Abstract. Random forests are a popular classification method based on an ensemble of a single type of decision tree. In the literature, there are many different types of decision tree algorithms, including C4.5, CART and CHAID. Each type of decision tree algorithms may capture different information and structures. In this paper, we propose a novel random forest algorithm, called a hybrid random forest. We ensemble multiple types of decision trees into a random forest, and exploit diversity of the trees to enhance the resulting model. We conducted a series of experiments on six text classification datasets to compare our method with traditional random forest methods and some other text categorization methods. The results show that our method consistently outperforms these compared methods. Key words: Random Forests, Hybrid Random Forest, Classification, Decision Tree
1 Introduction
Random forests [1, 2] are a popular classification method which builds an ensemble of a single type of decision tree. The decision trees are often either built using C4.5 [3] or CART [4], but only one type was exploited within a single random forest. In recent years, random forests have attracted increasing attention due to (1) its competitive performance compared with other classification methods, especially for high-dimensional data, (2) algorithmic intuitiveness and simplicity, and (3) its most important capability - "ensemble" using bagging [5] and stochastic discrimination [2].
The most popular forest construction procedure was proposed by Breiman [1], novelly using bagging to generate training data subsets for building individual trees. A subspace of features is then randomly selected at each node to grow branches of a decision tree. The trees are then combined as an ensemble into a random forest [1].

2
In the literature, different types of decision trees algorithms have been proposed, including C4.5, CART and CHAID [6]. Each type of decision tree algorithms employs a different tree building process and captures different discriminative information.
Random forests gain some of their performance advantage through the diversity of the trees in the resulting ensemble. We can add another kind of diversity to the random forest framework by removing any potential bias from using a single type of decision tree. We propose to use several different types of decision trees for each training data subset, and select the best tree as the individual tree classifier in the random forest model.
Our method is motivated by the experiences of foresters in dealing with the development and care of hybrid forests. An important concept in Forestry is that of a "hybrid forest." Such a forest uses multiple tree species as a mixed planting in accordance with soil structure (moisture, nutrients, acidity). This method has demonstrated highly economic, ecological and practical value in forestry research. Mimicing this idea, we have developed a hybrid random forest method to explore whether we can further enhance the classification performance of a random forest ensemble classifier. Specifically, we build three different types of tree classifiers (C4.5, CART and CHAID) for each training data subset. We then evaluate the performance of the three classifiers and select the best tree. In this way, we build a hybrid random forest which may include different types of decision trees in the ensemble. The added diversity of the decision trees can effectively improve the accuracy of each tree in the forest, and hence the accuracy of the ensemble.
To demonstrate the effectiveness of our proposed method, we apply it to the popular application of text classification. With the ever-increasing volume of text data from the Internet, databases, and archives, text categorization has become a key technique for handling and organizing text data. It has received growing attention in recent years. A set of popular and mature machine learning approaches have been deployed for categorizing text documents, including random forests [8], support vector machines (SVM) [9], naive Bayes (NB) [10], k-nearest neighbors (KNN) [11], and decision trees. Due to algorithmic simplicity and prominent classification performance for high dimensional data, random forests have become a preferred method.
In this paper, we compare the performance of our random forest with that of other three random forest methods, i.e., C4.5 random forest, CART random forest and CHAID random forest, and other three mainstream text categorization methods, i.e., support vector machines, naive Bayes and k-nearest neighbors, on six datasets. The experimental results show that our hybrid random forest achieves improved classification performance over these six compared methods.
The rest of this paper is organized as follows. Section 2 introduces the framework for building a hybrid Random Forest, and gives a brief analysis of the method. The evaluation methods are presented in Section 3, we present experimental results in Section 4. Our conclusions and future work are presented in Section 5.

3
2 Hybrid Random Forests
In this section, we introduce a general framework for building hybrid random forests. We then briefly review three types of decision tree algorithms, i.e., C4.5, CART and CHAID. We also present our hybrid random forest algorithm that integrates the best trees from the different types of decision tree algorithms.

2.1 Framework for Building Hybrid Random Forest

As an ensemble learner, the performance of a random forest is highly dependent on two factors: the diversity among the trees and the accuracy of each tree [12]. Diversity is commonly obtained by using bagging and random subspace sampling. We introduce a further element of diversity by using different types of trees.
Continuing our analogy with forestry, the different data subsets from bagging represents the "soil structures." Different decision tree algorithms represent "different tree species". Our approach has two key aspects: one is to use three types of decision tree algorithms to generate three different tree classifiers for each training data subset; the other is to evaluate the accuracy of each tree as the measure of tree importance. In this paper, we use the out-of-bag accuracy to assess the importance of a tree.
Following Breiman, we use bagging to generate a series of training data subsets from which we build trees. For each tree, the data subset used to grow the tree is called the "in-of-bag" (IOB) data and the remaining data subset is called the "out-of-bag" (OOB) data. Since OOB data is not used for building trees we can use this data to objectively evaluate each tree's accuracy and importance. The OOB accuracy gives an unbiased estimate of the true accuracy of a model.
Given n instances in a training dataset D and a tree classifier hk(IOBk) built from the k'th training data subset IOBk, we define the OOB accuracy of the tree hk(IOBk) for each di  D as:

OOBAcck =

n i=1

I (hk (di )

=

yi;

di

/

I OBk )

n i=1

I (di

/

I OBk )

(1)

where I(.) is an indicator function. The larger the OOBAcck, the better classification quality a tree has.
We use the out-of-bag data subset OOBi to calculate the out-of-bag accuracies of the three types of trees (C4.5, CART and CHAID) with evaluation values A1, A2 and A3 respectively.
Fig. 1 illustrates the procedure for building a hybrid random forest model. Firstly, a series of IOB/OOB datasets are generated from the entire training dataset by bagging. Then, three types of tree classifiers (C4.5, CART and CHAID) are built using each IOB dataset. The corresponding OOB dataset is used to calculate the OOB accuracies of the three tree classifiers. Finally, we select the tree with the highest OOB accuracy as the final tree classifier, which is included in the hybrid random forest.

4
Fig. 1. The Hybrid Random Forests framework.
Building a hybrid random forest model in this way will increase the diversity among the trees. The classification performance of each individual tree classifier is also maximized. 2.2 Decision Tree Algorithms The core of our approach is the diversity of decision tree algorithms in our random forest. Different decision tree algorithms grow structurally different trees from the same training data. Selecting a good decision tree algorithm to grow trees for a random forest is critical for the performance of the random forest. Few studies have considered how different decision tree algorithms affect a random forest. We do so in this paper.
The common decision tree algorithms are as follows: Classification Trees 4.5 (C4.5) is a supervised learning classification algorithm used to construct decision trees. Given a set of pre-classified objects, each described by a vector of attribute values, we construct a mapping from attribute values to classes. C4.5 uses a divide-and-conquer approach, which is similar to recursive partitioning, to grow decision trees. C4.5 selects the test that maximizes the information gain ratio (IGR) [3].

5
Classification and Regression Tree (CART) is a recursive partitioning method that can be used for both regression and classification. Beginning with the entire dataset, a tree is constructed by splitting subsets of the dataset by considering all predictor variables for splitting. The best predictor is chosen at each node using a variety of impurity or diversity measures. The goal is to produce subsets of the data which are homogeneous with respect to the target variable [4]. The main difference between C4.5 and CART is the test selection and evaluation process.
Chi-squared Automatic Interaction Detector (CHAID) method is based on the chi-square test of association. A CHAID decision tree is constructed by repeatedly splitting subsets of the space into two or more nodes. To determine the best split at any node, any allowable pair of categories of the predictor variables is merged until there is no statistically significant difference within the pair with respect to the target variable [6, 7].
From these decision tree algorithms, we can see that the difference lies in the way to split a node, such as the split functions and binary branches or multibranches. In this work we use these different decision tree algorithms to build a hybrid random forest.
2.3 Algorithm
In this subsection, we present our hybrid random forest algorithm which integrates the three types of tree classifiers. The detailed steps are introduced in Algorithm 1.
In Algorithm 1, lines 10-17 loop to build K decision trees. In the loop, Line 11 samples the training data D by sampling with replacement to generate an in-of-bag data subset IOBi for building a decision tree. Lines 12-15 build three types of tree classifiers (C4.5, CART and CHAID). In this procedure, Line 13 calls the function createT reej() to build a tree classifier. Line 14 calculates the out-of-bag accuracy of the tree classifier. After this procedure, Line 16 selects the tree classifier with the maximum out-of-bag accuracy. K decision trees are thus generated to form a hybrid random forest model M .
Generically, function createT reej() first creates a new node. Then, it tests the stopping criteria to decide whether to return to the upper node or to split this node. If we chose to split this node, then we randomly select m features as a subspace for node splitting. These features are used as candidates to generate the best split to partition the node. For each subset of the partition, createT reej() is called again to create a new node under the current node. If a leaf node is created, it returns to the parent node. This recursive process continues until a full tree is generated.
3 Evaluation Methods
We use two measures to evaluate the classification performance of the hybrid random forest, the test accuracy and the F1 metric. The test accuracy measures

6
Algorithm 1 Hybrid Random Forest Algorithm
1: Input: 2: - D : the training dataset, 3: - A : the features space {A1, A2, ..., AM }, 4: - Y : the class features space {y1, y2, ..., yq}, 5: - K : the number of trees, 6: - m : the size of subspaces.
7: 8: Output: A random forest M ; 9: Method: 10: for i = 1 to K do 11: draw a bootstrap sample in-of-bag data subset IOBi and out-of-bag data
subset OOBi from training dataset D; 12: for j = 1 to 3 do 13: hi,j(IOBi) = createT reej(); 14: use out-of-bag data subset OOBi to calculate the out-of-bag accuracy
OOBAcci,j of the tree classifier hi,j(IOBi) by Equation (1); 15: end for 16: select hi(IOBi) with the highest out-of-bag accuracy OOBAcci as best
tree i; 17: end for 18: combine the K optimal tree classifiers h1(IOB1), h2(IOB2), ..., hK (IOBK )
into a random forest M
19: 20: Function createTree() 21: create a new node N ; 22: if stopping criteria is met then 23: return N as a leaf node; 24: else 25: randomly select m features as a subspace; 26: use these m features as candidates to generate the best split for the node
to be partitioned; 27: call createTree() for each split; 28: end if 29: return N ;

the performance of a random forest on a separate test dataset. The F1 metric is a commonly used measure of classification performance.
Test Accuracy. Let Dt be a test dataset and Yt be the class labels. Given di  Dt, the number of votes for di on class j is

K
N (di, j) = I(hk(di) = j)
k=1

(2)

7

The test accuracy is calculated as

n

Acc

=

1 n

I(N (di, yi) - maxj=yi N (di, j) > 0)

i=1

(3)

where n is the number of objects in Dt and yi indicates the true class of di. F1 Metric. To evaluate the performance of classification methods in dealing

with an unbalanced class distribution, we use the F1 metric introduced by Yang

and Liu [13]. This measure is equal to the harmonic mean of recall () and

precision (). The overall F1 score of the entire classification problem can be

computed by a micro-average and a macro-average.

Micro-averaged F1. This is computed globally over all classes, and em-

phasizes the performance of a classifier on common classes. Define  and  as

follows:

=

q i=1

q i=1

T

Pi

(T Pi + F

Pi)

,

=

q i=1

T

Pi

q i=1

(T

Pi

+

F

Ni)

(4)

where q is the number of classes. T Pi (True Positives) is the number of objects correctly predicted as class i, F Pi (False Positives) is the number of objects that are predicted to belong to class i but do not. The micro-averaged F1 is computed

as:

M icroF 1

=

2 +

(5)

Macro-averaged F1. This is first computed locally over each class, and then the average over all classes is taken. It emphasizes the performance of a classifier on rare categories. Define  and  as follows:

i

=

(T

T Pi Pi + F

Pi)

,

i

=

T Pi (T Pi + F Ni)

F 1 for each category i and the macro-averaged F1 are computed as:

(6)

F 1i

=

2ii i + i

,

M acroF 1 =

q i=1

F

1i

q

(7)

The larger the MicroF1 and MacroF1 values are, the better the classification

performance of the classifier.

4 Experiments
In this section, we conduct experiments to demonstrate the effectiveness of the hybrid random forest algorithm for classifying text data. Text datasets with various sizes and characteristics are used in the experiments. The experimental results show that the hybrid random forest algorithm not only outperforms singletree type random forest algorithms, i.e., C4.5 RF, CART RF and CHAID RF, in classification accuracy, but also outperforms other three mainstream text categorization methods, i.e., SVM, NB and KNN.

8
4.1 Datasets
In the experiments, we used six real-world text datasets. These text datasets are selected due to their diversities in the number of terms or features, the number of documents, and the number of classes. Their dimensionalities vary from 2000 to 11,465, numbers of instances vary from 918 to 11,162 and the minority class rate varies from 0.32% to 6.43%. In each text dataset, we randomly select 70% of documents as the training dataset, and the remaining data as the test dataset. Detailed information of the six text datasets is listed in Table 1.

Table 1. Summary statistic of 6 text datasets.

Dataset
Fbis Re0 Oh5 Re1 Wap Ohscal

#Terms
2000 2886 3012 3758 8460 11465

#Documents
2463 1504 918 1657 1560 11162

#Classes
17 13 10 25 20 10

%Minority class
1.54 0.73 6.43 0.6 0.32 6.35

These datasets are frequently used as text document classification benchmark data [14]. Dataset Fbis was compiled from Foreign Broadcast Information Service TREC-5 [15]. The datasets Re0 and Re1 were selected from Reuters21578 text categorization test collection Distribution 1.0 [16]. Datasets Oh5 and Ohscal are from the OHSUMED subset of the MEDLINE database [17]. Wap is from the WebACE project (WAP) [18].
4.2 Test Accuracy Improvement
The purpose of this experiment is to evaluate the effect of the hybrid random forest method on accuracy. The six text datasets were analyzed and results were compared with other three random forest methods (C4.5 RF, CART RF and CHAID RF). For each text dataset, we ran each random forest algorithm against different sizes of feature subspaces. Since the number of features in these datasets was very large, we started with a subspace of 15 features and increased the subspace with 5 more features each time. For a given subspace size, we built 100 trees for each random forest model. In order to obtain a stable result, we built 80 random forest models for each subspace size, each dataset and each algorithm, and computed the averages of the test accuracy as the final result for comparison.
Fig. 2 shows the plots of the average test accuracy of the four random forest models in different sizes generated with the four methods from the six text datasets. For the same number of features, the higher the accuracy, the better the result. From these figures, we can observe that the hybrid random forest

9

Accuracy

Accuracy

Fbis
0.86

0.84

0.82

0.80

0.78 0.76

C4.5_RF CART_RF CHAID_RF Hybrid_RF

10

20

30

40

50

60

70

80

90

100

Number of features

0.93

Oh5

0.92 0.91

0.90 0.89

0.88 0.87 0.86 0.85 0.84

C4.5_RF CART_RF CHAID_RF Hybrid_RF

10

20

30

40

50

60

70

80

90

100

Number of features

0.82

Wap

0.80

0.78

0.76

0.74

0.72

C4.5_RF

CART_RF

0.70

CHAID_RF

Hybrid_RF

0.68

20

30

40

50

60

70

80

90

100

Number of features

Accuracy

Accuracy

Accuracy

0.85

Re0

0.80

0.75

0.70

0.65

C4.5_RF

0.60

CART_RF CHAID_RF

Hybrid_RF

0.55

20

30

40

50

60

70

80

90

100

Number of features

0.84

Re1

0.81

0.78

0.75

0.72 0.69

C4.5_RF CART_RF CHAID_RF Hybrid_RF

20

30

40

50

60

70

80

90

100

Number of features

0.82

Ohscal

0.80

0.78

0.76

0.74

0.72 0.70 0.68

C4.5_RF CART_RF CHAID_RF Hybrid_RF

30

40

50

60

70

80

90

100 110 120

Number of features

Accuracy

Fig. 2. Test accuracy changes against the number of features in the subspace on the 6 text datasets.

algorithm consistently performs better than the other three random forest algorithms. The advantages are more obvious in the smaller subspaces. The hybrid random forest algorithm quickly achieves high accuracy as the subspace size increases. The other three random forest algorithms require larger subspaces to achieve a similar accuracy. These results illustrate that the hybrid random forest algorithm outperforms the other three random forest algorithms in the classification accuracy results on all the six text datasets.
To further investigate the performance of the hybrid random forest, we computed the average accuracy of the trees in each single-type random forest. This is compared to the average accuracy of the trees of the same type within the one hybrid random forest. In all comparisons, the subspace size of M features

10

Table 2. A comparison of the average accuracy of trees within a single-type random forest and the average accuracy of trees of that same type within the hybrid random forest.

Name

C4.5

C4.5 RF Hybrid

CART

CHAID

RF CART RF Hybrid RF CHAID RF Hybrid RF

Fbis 0.6379 0.6489 0.6102 0.6414 0.6382 0.6536

Re0 0.6132 0.6324 0.6271 0.6478 0.6171 0.6304

Oh5 0.6516 0.6664 0.6134 0.6515 0.6245 0.6607

Re1 0.6611 0.6793 0.6058 0.6608 0.6516 0.6718

Wap 0.5267 0.5343 0.5086 0.5396 0.5195 0.5297

Ohscal 0.5391 0.5448 0.4732 0.5004 0.4665 0.5204

was used, where M is the total number of features in the dataset. The results are shown in Table 2. For example, for tree type C4.5 and dataset Fbis, the average accuracy of all trees from the random forest built using C4.5 (named as C4.5 RF) is 0.6379. The average accuracy of all C4.5 trees from the hybrid random forest (named as Hybrid RF) is 0.6489. It is clearly seen in Table 2 that tree classifiers of any given type in our hybrid random forest always have higher average classification accuracy than those using only trees of the same one type.
4.3 Performance Comparisons of Other Text Classification Method
We conduct a further experimental comparison against other three widely used text categorization methods, i.e., support vector machines (SVM), Naive Bayes (NB), and k-nearest neighbor (KNN). The SVM uses a linear Kernel with a regularization parameter of 0.03125, which is often used in text categorization. For Naive Bayes, we adopted the multi-variate Bernoulli event model that is frequently used in text classification [19]. For k-nearest neighbor (KNN), we set the number of neighbors as 13. In the experiments, we use WEKA's implementation for these three text classification methods [20]. We use a single subspace size of 90 features in all the six datasets to run the random forest algorithms, which provides a consistent result as shown in Fig. 2. In order to obtain stable results, we built 20 random forest models for each random forest algorithm and each dataset, and present the average results, we can see that the range of values are less than ±0.005 and the hybrid trees are always more accurate.
The comparison results are listed in Fig. 3, 4 and 5. While the improvement is often quite small, there is always an improvement demonstrated. We observe that our proposed method always outperforms the compared mainstream text categorization methods.
5 Conclusion and Future Work
We have presented a new hybrid random forest algorithm which increases diversity amongst the ensemble of trees by choosing different tree algorithms. We

11
Fig. 3. Accuracy of the seven model builders.
Fig. 4. MicroF1 for the seven model builders.
Fig. 5. MacroF1 for the seven model builders. demonstrate the advantage of our method in categorization. Our algorithm consistently improves classification performance. In the future work, we will consider alternative options for combining the three types of trees, rather than using the simple approach of keeping just one tree. For example, the results from the three trees might be combined into a single decision. Finally, alternative decision tree algorithms, or even other types of model builders, will be considered within this hybrid framework.

12
Acknowledgements
This research is supported in part by Shenzhen New Industry Development Fund under grant No.CXB201005250021A.
References
1. Breiman, L.: Random forests. Machine Learning 45(1), 5-32 (2001). 2. Ho, T.K.: The random subspace method for constructing decision forests. IEEE
Transactions on Pattern Analysis and Machine Intelligence 20(8), 832-844 (1998). 3. Quinlan, J.R.: C4.5: Programs for Machine Learning. Morgan Kaufmann, San Ma-
teo, Calif (1993). 4. Breiman, L., Friedman, J.H., Olshen R.A., Stone, C.J.: Classification and Regres-
sion Trees. Monterey, CA. Wadsworth and Brooks/Cole Advanced Books and Software (1984). 5. Breiman, L.: Bagging predictors. Machine Learning 24(2), 123-140 (1996). 6. Biggs, D., Suen, E.: A method of choosing multiway partitions for classification and decision trees. Journal of Applied Statistics 18(1), 49-62 (1991). 7. Ture, M., Kurt, I., Turhan Kurum, A., Ozdamar, K.: Comparing classification techniques for predicting essential hypertension. Expert Systems with Applications 29(3), 583-588 (2005). 8. Klema, J., Almonayyes, A.: Automatic categorization of fanatic texts using random forests. Kuwait Journal of Science and Engineering 33(2), 1-18 (2006). 9. Begum, N., Fattah M.A., Ren, F.J.: Automatic text summarization using support vector machine. International Journal of Innovative Computing Information and Control 5(7), 1987-1996 (2009). 10. Chen, J.N., Huang, H.K., Tian, S.F., Qu, Y.L.: Feature selection for text classification with naive bayes. Expert Systems with Applications 36(3), 5432-5435 (2009). 11. Tan, S.: Neighbor-weighted K-nearest neighbor for unbalance text corpus. Expert Systems with Applications 28(4), 667-671 (2005). 12. Dietterich, T.G.: Machine learning research: Four current directions. AI Magazine 18(4), 97-136 (1997). 13. Yang, Y., Liu, X.: A re-examination of text categorization methods. In: ACM SIGIR 1999, pp. 42-49 (1999). 14. Han, E., Karypis, G.: Centroid-based document classification: Analysis & experimental results. In: ECML PKDD 2000, pp. 424-431 (2000). 15. TREC. Text retrieval conference. Available at: <http://trec.nist.gov>. 16. Lewis, D.D.: Reuters-21578 text categorization test collection distribution 1.0 (2011). Available at: <http://www.research.att.com/ lewis>. 17. Hersh, W., Buckley, C., Leone, T.J., Hickam, D.: OHSUMED: An interactive retrieval evaluation and new large test collection for research. In: SIGIR 1994, pp. 192-201 (1994). 18. Moore, J., Han, E., Boley, D., Gini, M., Gross, R., Hastings, K., Karypis, G., Kumar, V., Mobasher, B.: Web page categorization and feature selection using association rule and principal component clustering. In: WITS 1997 (1997). 19. McCallum, A., Nigam, K.: A comparison of event models for naive bayes text classification. In: AAAI Workshop 1998, pp. 41-48 (1998). 20. Witten, I.H., Frank, E., Hall, M.A.: Data Mining: Practical Machine Learning Tools and Techniques. Morgan Kaufmann, Burlington, third edition (2011).

